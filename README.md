
# Beijing Air Quality Prediction (PM2.5)

**Time Series Forecasting & Machine Learning Portfolio**  
*(åŒ—äº¬ç©ºæ°”è´¨é‡é¢„æµ‹é¡¹ç›® â€” å®Œæ•´æœºå™¨å­¦ä¹ æ—¶é—´åºåˆ—åˆ†ææµç¨‹)*

---

## ğŸ“˜ Overview

This project presents an endâ€‘toâ€‘end machine learning workflow for predicting **PM2.5 concentration levels** in Beijing using the **UCI PRSA dataset (2010â€“2014)**.  
It highlights advanced **timeâ€‘series feature engineering**, treeâ€‘based ensemble modeling, rigorous **TimeSeries Crossâ€‘Validation**, and visualization-driven interpretation.

This project was developed as part of an academic portfolio for research and upperâ€‘year project applications.

---

## ğŸš€ Key Features (What Makes This Project Strong)

### ğŸ”¹ 1. Advanced Timeâ€‘Series Feature Engineering  
Implemented in `src/feature_engineering.py`:

- **Lag Features** (`pm25_lag1`, `pm25_lag24`) â†’ capture short-term & daily temporal dependence  
- **Rolling Window Features** â†’ 24â€‘hour smoothed trends  
- **Cyclical Encoding**  
  Converts hour / month / weekday into sineâ€‘cosine components to keep continuity  
  (`23 â†’ 0` becomes close on a circle)  
- **Meteorological Historical Lags** for temperature, humidity, wind speedâ€¦

### ğŸ”¹ 2. Robust Ensemble Modeling  
Implemented in `modeling_rf.py` & `modeling_xgb.py`:

- **Random Forest Regressor**
- **XGBoost Regressor** (best model)
- Trains with **TimeSeriesSplit** (prevents data leakage)

### ğŸ”¹ 3. Clear Interpretation & Analysis

- Feature Importance (builtâ€‘in RF & XGB)
- Actual vs Predicted line charts
- Residual distribution analysis

---

## ğŸ“‚ Project Structure

```
Air-Quality-Portfolio-Project/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â””â”€â”€ cleaned/
â”‚
â”œâ”€â”€ images/                 # Plots (feature importance, predictions)
â”œâ”€â”€ models/                 # Saved trained models
â”‚
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ AirQuality_Report_CNfont_Improved.ipynb
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ test_data_cleaning.py
â”‚   â”œâ”€â”€ feature_engineering.py
â”‚   â”œâ”€â”€ modeling_rf.py
â”‚   â”œâ”€â”€ modeling_xgb.py
â”‚   â””â”€â”€ visualization_pm25.py
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ›  Tech Stack

- **Python 3.9+**
- Pandas / NumPy
- scikitâ€‘learn
- XGBoost
- Matplotlib / Seaborn
- Jupyter Notebook

---

## âš™ï¸ Methodology

### 1. Data Cleaning  
File: `test_data_cleaning.py`

- Linear interpolation for missing timestamps  
- Drop incomplete rows  
- Basic quality control checks

---

### 2. Feature Engineering  
File: `feature_engineering.py`

#### âœ” Lag Features  
Captures autocorrelation patterns:

```
pm25_lag1   # previous hour
pm25_lag24  # previous day same hour
```

#### âœ” Rolling Window Features  
Smooths noisy short-term variance.

#### âœ” Cyclical Encoding  
Example (Hour â†’ sin/cos):

```python
df["hour_sin"] = np.sin(2 * np.pi * df["hour"] / 24)
df["hour_cos"] = np.cos(2 * np.pi * df["hour"] / 24)
```

Ensures 23:00 and 00:00 remain close in encoded feature space.

---

### 3. Model Training & Evaluation  
Files:  
- `modeling_rf.py`  
- `modeling_xgb.py`

#### Validation:
Uses **5â€‘fold TimeSeriesSplit** to ensure no future leakage.

#### Metrics:
- RMSE
- MAE
- RÂ² score

---

## ğŸ“Š Performance Summary

| Model | Feature Set | Test RÂ² | Notes |
|------|-------------|---------|-------|
| **Linear Regression** | Weather only | ~0.11 | Strong underfitting |
| **Quadratic Temp Model** | Weather + TempÂ² | ~0.12 | Very small gain |
| **Random Forest** | Lags + Cyclical | **~0.94** | Strong performance |
| **XGBoost** | Lags + Cyclical | **~0.945** | Best model |

---

## ğŸ“ˆ Key Plots (in `images/`)

- Timeâ€‘series prediction vs actual PM2.5  
- Residual distribution  
- Model comparison  
- Feature importance (RF & XGB)

---

## ğŸ§ª Quick Start

### Step 1 â€” Install dependencies  
```
pip install -r requirements.txt
```

### Step 2 â€” Clean data  
```
python src/test_data_cleaning.py
```

### Step 3 â€” Generate engineered features  
```
python src/feature_engineering.py
```

### Step 4 â€” Train baseline + ensemble models  
```
python src/modeling_rf.py
```

### Step 5 â€” Train production XGBoost model  
```
python src/modeling_xgb.py
```

---

## ğŸ”® Future Improvements

- Hyperparameter tuning (Optuna / GridSearchCV)
- Add LightGBM & CatBoost
- Train deep learning models (LSTM / GRU)
- Deploy a Streamlit dashboard
- Integrate SHAP for advanced model explainability

---

## ğŸ‘¤ Author

**edg663**  
Educational Portfolio Project  
GitHub: https://github.com/edg663/Air-Quality-Portfolio-Project
